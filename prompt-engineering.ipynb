{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11176010,"sourceType":"datasetVersion","datasetId":6975304}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"18ab9fe8abd84251a729fefe3bfa0ad9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d09e6258784367bee4067b800fceb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48d7994725b24a28ac9c79418c5111a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7417c346afc24a98832d481d58167b69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae6c27aa30f34ddeba9abd06bf96cafb","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93bdf8798f5f42718bb89b101e54c682","value":2}},"7d5805c372ee40cdb860c69d0d87c87b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e66c28e3e54a3ea111ef70b229d8a9","placeholder":"​","style":"IPY_MODEL_23d09e6258784367bee4067b800fceb9","value":"Loading checkpoint shards: 100%"}},"93bdf8798f5f42718bb89b101e54c682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae6c27aa30f34ddeba9abd06bf96cafb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11f7e2e0acc40128f1ffc5f36b5b029":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d5805c372ee40cdb860c69d0d87c87b","IPY_MODEL_7417c346afc24a98832d481d58167b69","IPY_MODEL_f73f2c3f4e1347dcb0ff085a27d1927a"],"layout":"IPY_MODEL_48d7994725b24a28ac9c79418c5111a6"}},"b5dbaea6b0ce4330921b1486f1c4f7d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8e66c28e3e54a3ea111ef70b229d8a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73f2c3f4e1347dcb0ff085a27d1927a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18ab9fe8abd84251a729fefe3bfa0ad9","placeholder":"​","style":"IPY_MODEL_b5dbaea6b0ce4330921b1486f1c4f7d8","value":" 2/2 [00:34&lt;00:00, 17.13s/it]"}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up environment","metadata":{},"attachments":{}},{"cell_type":"markdown","source":"Check cuda version","metadata":{"id":"NdvT46W7JVp-"},"attachments":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"WsGKOY7CJO_p","outputId":"faf19e6b-cd94-427a-c135-534112e1cf10","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Change CUDA memory config","metadata":{"id":"o68lGIFRPq2a"},"attachments":{}},{"cell_type":"code","source":"!export 'PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True'","metadata":{"id":"Jg-aQ_mEPhcr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Install packages","metadata":{"id":"U0zIj5U8IYpW"},"attachments":{}},{"cell_type":"code","source":"%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n%pip install --upgrade datasets transformers bitsandbytes\n%pip install --upgrade qwen-vl-utils[decord]","metadata":{"id":"qxeL2VoxJDIj","outputId":"8a8366e4-eb9a-47f3-b3ef-96e2f94e6224","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using Qwen 2.5-VL one time with better prompt","metadata":{},"attachments":{}},{"cell_type":"markdown","source":"Import packages","metadata":{"id":"IQdxPe5HOCAo"},"attachments":{}},{"cell_type":"code","source":"import time\nimport csv\nimport torch\nfrom datasets import load_dataset\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM\nfrom qwen_vl_utils import process_vision_info\nfrom huggingface_hub import login\nfrom kaggle_secrets import UserSecretsClient","metadata":{"id":"6pCgmEBcN-sq","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T08:47:46.303096Z","iopub.execute_input":"2025-04-09T08:47:46.303697Z","iopub.status.idle":"2025-04-09T08:47:46.307737Z","shell.execute_reply.started":"2025-04-09T08:47:46.303671Z","shell.execute_reply":"2025-04-09T08:47:46.306874Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"Login to HuggingFace","metadata":{}},{"cell_type":"code","source":"login(token=UserSecretsClient().get_secret(\"HuggingFace\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T08:47:46.311205Z","iopub.execute_input":"2025-04-09T08:47:46.311521Z","iopub.status.idle":"2025-04-09T08:47:46.544014Z","shell.execute_reply.started":"2025-04-09T08:47:46.311491Z","shell.execute_reply":"2025-04-09T08:47:46.543315Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Load dataset and model","metadata":{"id":"AF2UMdBjKH_K"},"attachments":{}},{"cell_type":"code","source":"dataset = load_dataset(\"lmms-lab/AISG_Challenge\")\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n    quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n    device_map=\"cuda:0\")\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")\nmistral_model = AutoModelForCausalLM.from_pretrained(\n    \"mistralai/Mistral-7B-Instruct-v0.3\",\n    quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n    device_map=\"cuda:1\")\nmistral_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")","metadata":{"id":"bWUoIoHuKK0n","outputId":"dce77522-e396-416e-9c57-d64a9dd45a08","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T08:47:46.544727Z","iopub.execute_input":"2025-04-09T08:47:46.544957Z","iopub.status.idle":"2025-04-09T08:50:11.631127Z","shell.execute_reply.started":"2025-04-09T08:47:46.544937Z","shell.execute_reply":"2025-04-09T08:50:11.630192Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"684213b802e24020962d9f743e5326f4"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83bd251921aa411bb5f733716d2044c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e13da1d3e01439887a8bcce5602d6bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/141k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9fa979b594f84a2b945b8ec1d9bdc575"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/587k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076e0ac077564ac79d3121102684b5af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c1bdbcb35b4183b9a7f9e1af271741"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e3ce4ad7b127422a99d8e39a6f969025"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"Download video function","metadata":{"id":"_VIcN_9gKVbk"},"attachments":{}},{"cell_type":"code","source":"def retrieve_video(video_id):\n    filename = f\"{video_id}.mp4\"\n    video_path = f\"../input/videos/{filename}\"\n    return video_path","metadata":{"id":"FOr5RWLAKS1m","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T08:50:11.632851Z","iopub.execute_input":"2025-04-09T08:50:11.633127Z","iopub.status.idle":"2025-04-09T08:50:11.636698Z","shell.execute_reply.started":"2025-04-09T08:50:11.633089Z","shell.execute_reply":"2025-04-09T08:50:11.635986Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Improve prompt","metadata":{}},{"cell_type":"code","source":"def improve_prompt(question):\n    actual_question = question.split('\\n')[0]\n    prompt = f\"Generalize the question using only one of the most appropriate 5W1H formats (Who, What, When, Where, Why, How).\\nOriginal question: {actual_question}\\nRewritten question:\"\n    model_inputs = mistral_tokenizer([prompt], return_tensors=\"pt\").to(mistral_model.device)\n    generated_ids = mistral_model.generate(**model_inputs, max_new_tokens=100)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids) :] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)\n    ]\n    output_text = mistral_tokenizer.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )[0]\n    return output_text + \" \" + question","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T09:01:44.807996Z","iopub.execute_input":"2025-04-09T09:01:44.808395Z","iopub.status.idle":"2025-04-09T09:01:44.813548Z","shell.execute_reply.started":"2025-04-09T09:01:44.808360Z","shell.execute_reply":"2025-04-09T09:01:44.812647Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"Process sample","metadata":{"id":"Bii44pICKZmU"},"attachments":{}},{"cell_type":"code","source":"def process_test_case(example):\n    video_id = example[\"video_id\"]\n    question = example[\"question\"]\n    question_prompt = example[\"question_prompt\"]\n    expected_answer = example[\"answer\"]\n    video_path = retrieve_video(video_id)\n\n    prompt = f\"{improve_prompt(question)}\\n{question_prompt}\\nAnswer in English only.\"\n    \n    conversation = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"video\",\n                    \"video\": video_path,\n                    \"max_pixels\": 240 * 426,\n                    \"fps\": 1,\n                },\n                {\"type\": \"text\", \"text\": prompt},\n            ],\n        }\n    ]\n\n    text = processor.apply_chat_template(\n        conversation, tokenize=False, add_generation_prompt=True\n    )\n    image_inputs, video_inputs, video_kwargs = process_vision_info(conversation, return_video_kwargs=True)\n    inputs = processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n        **video_kwargs,\n    )\n    inputs = inputs.to(model.device)\n\n    generated_ids = model.generate(**inputs, max_new_tokens=1280)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    output_text = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )[0]\n    print(f\"Prompt:\\n{prompt}\")\n    print(f\"Video URL: {example['youtube_url']}\")\n    print(f\"Question:\\n{question}\\n{question_prompt}\")\n    print(f\"Answer: {output_text}\")\n    return example['qid'], output_text","metadata":{"id":"FOu2jwkdKeGq","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T09:00:25.718915Z","iopub.execute_input":"2025-04-09T09:00:25.719273Z","iopub.status.idle":"2025-04-09T09:00:25.725686Z","shell.execute_reply.started":"2025-04-09T09:00:25.719243Z","shell.execute_reply":"2025-04-09T09:00:25.724974Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"Run test cases","metadata":{"id":"sKsDjKFWKjKv"},"attachments":{}},{"cell_type":"code","source":"start_time = time.time()\noutput_file = \"./results.csv\"\nwith open(output_file, mode=\"w\", newline=\"\") as file:\n    writer = csv.writer(file)\n    writer.writerow([\"qid\", \"pred\"])\n    sample = dataset['test'].filter(lambda x: x['qid'] == '0008-3')[0]\n    qid, pred = process_test_case(sample)\n    writer.writerow([qid, pred])\n    '''\n    for sample in dataset['test']:\n        print(f\"processing qid {sample['qid']}\")\n        qid, pred = process_test_case(sample)\n        writer.writerow([qid, pred])\n    '''\nend_time = time.time()\nprint(f\"Time taken: {end_time - start_time} seconds\")","metadata":{"id":"TC2df2I0vPXv","trusted":true,"execution":{"iopub.status.busy":"2025-04-09T09:01:47.838434Z","iopub.execute_input":"2025-04-09T09:01:47.838725Z","iopub.status.idle":"2025-04-09T09:01:59.104934Z","shell.execute_reply.started":"2025-04-09T09:01:47.838702Z","shell.execute_reply":"2025-04-09T09:01:59.103915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30de1fc0f99349678e84fbe7fd7af62f"}},"metadata":{}},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Prompt: How did the last person in the video open the bottle? Did the last person in the video open the bottle with a knife while the first two people failed in their attempts?\nPlease state your answer with a brief explanation.\nAnswer in English only.\nVideo URL: https://www.youtube.com/shorts/sj81PWrerDk\nQuestion:\nDid the last person in the video open the bottle with a knife while the first two people failed in their attempts?\nPlease state your answer with a brief explanation.\nAnswer: No, the last person in the video successfully opened the Coca-Cola bottle using a knife. The first two individuals in the video were shown attempting to open bottles but did not use a knife; instead, they seemed to be struggling or failing in their methods.\nTime taken: 11.261261940002441 seconds\n","output_type":"stream"}],"execution_count":29}]}