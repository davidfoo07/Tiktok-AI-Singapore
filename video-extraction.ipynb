{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NdvT46W7JVp-"
   },
   "source": [
    "Check cuda version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsGKOY7CJO_p",
    "outputId": "faf19e6b-cd94-427a-c135-534112e1cf10",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "o68lGIFRPq2a"
   },
   "source": [
    "Change CUDA memory config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jg-aQ_mEPhcr",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!export 'PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "U0zIj5U8IYpW"
   },
   "source": [
    "Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxeL2VoxJDIj",
    "outputId": "8a8366e4-eb9a-47f3-b3ef-96e2f94e6224",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n",
    "%pip install --upgrade datasets transformers bitsandbytes ffmpeg-python\n",
    "%pip install --upgrade qwen-vl-utils[decord]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Qwen 2.5-VL one time with better prompt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "IQdxPe5HOCAo"
   },
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pCgmEBcN-sq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "import ffmpeg\n",
    "from datasets import load_dataset\n",
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
    "from qwen_vl_utils import process_vision_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tmp folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!mkdir /kaggle/tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AF2UMdBjKH_K"
   },
   "source": [
    "Load dataset and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bWUoIoHuKK0n",
    "outputId": "dce77522-e396-416e-9c57-d64a9dd45a08",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"lmms-lab/AISG_Challenge\")\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    \"Qwen/Qwen2.5-VL-7B-Instruct\",\n",
    "    quantization_config=BitsAndBytesConfig(load_in_8bit=True),\n",
    "    device_map=\"cuda:0\")\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-7B-Instruct\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_VIcN_9gKVbk"
   },
   "source": [
    "Download video function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOr5RWLAKS1m",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def retrieve_video(video_id):\n",
    "    filename = f\"{video_id}.mp4\"\n",
    "    video_path = f\"../input/videos/{filename}\"\n",
    "    return video_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract key frames timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_timestamp(question, video_path):\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": video_path,\n",
    "                    \"max_pixels\": 144 * 256,\n",
    "                    \"fps\": 1,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": f\"{question}\\nOnly return the timestamp relevant to the question in the format [mm:ss-mm:ss].\"},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        conversation, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info(conversation, return_video_kwargs=True)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        **video_kwargs,\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=1280)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "    \n",
    "    match = re.search(r\"\\[(\\d{1,2}):(\\d{2})-(\\d{1,2}):(\\d{2})\\]\", output_text)\n",
    "    m1, s1, m2, s2 = map(int, match.groups())\n",
    "    start = m1 * 60 + s1\n",
    "    end = m2 * 60 + s2\n",
    "    \n",
    "    return start, end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Bii44pICKZmU"
   },
   "source": [
    "Process sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FOu2jwkdKeGq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_test_case(example):\n",
    "    video_id = example[\"video_id\"]\n",
    "    question = example[\"question\"]\n",
    "    question_prompt = example[\"question_prompt\"]\n",
    "    expected_answer = example[\"answer\"]\n",
    "    \n",
    "    video_path = retrieve_video(video_id)\n",
    "    \n",
    "    prompt = f\"{question}\\n{question_prompt}\\nAnswer in English only.\"\n",
    "\n",
    "    start, end = extract_timestamp(question, video_path)\n",
    "    duration = end - start\n",
    "    output_path = os.path.join(\"/kaggle/tmp\", os.path.basename(video_path))\n",
    "    (\n",
    "    ffmpeg\n",
    "    .input(video_path, ss=start, t=duration)\n",
    "    .output(output_path)\n",
    "    .run(overwrite_output=True)\n",
    "    )\n",
    "    \n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"video\",\n",
    "                    \"video\": output_path,\n",
    "                    \"max_pixels\": 720*1280,\n",
    "                    \"fps\": 1,\n",
    "                },\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = processor.apply_chat_template(\n",
    "        conversation, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info(conversation, return_video_kwargs=True)\n",
    "    inputs = processor(\n",
    "        text=[text],\n",
    "        images=image_inputs,\n",
    "        videos=video_inputs,\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "        **video_kwargs,\n",
    "    )\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    generated_ids = model.generate(**inputs, max_new_tokens=1280)\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )[0]\n",
    "    \n",
    "    print(f\"Video URL: {example['youtube_url']}\")\n",
    "    print(f\"Question:\\n{question}\\n{question_prompt}\")\n",
    "    print(f\"Answer: {output_text}\")\n",
    "    \n",
    "    return example['qid'], output_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "sKsDjKFWKjKv"
   },
   "source": [
    "Run test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TC2df2I0vPXv",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "output_file = \"./results.csv\"\n",
    "with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"qid\", \"pred\"])\n",
    "    sample = dataset['test'].filter(lambda x: x['qid'] == '0957-0')[0]\n",
    "    qid, pred = process_test_case(sample)\n",
    "    writer.writerow([qid, pred])\n",
    "    '''\n",
    "    for sample in dataset['test']:\n",
    "        print(f\"processing qid {sample['qid']}\")\n",
    "        qid, pred = process_test_case(sample)\n",
    "        writer.writerow([qid, pred])\n",
    "    '''\n",
    "end_time = time.time()\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6975304,
     "sourceId": 11176010,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "18ab9fe8abd84251a729fefe3bfa0ad9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23d09e6258784367bee4067b800fceb9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "48d7994725b24a28ac9c79418c5111a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7417c346afc24a98832d481d58167b69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ae6c27aa30f34ddeba9abd06bf96cafb",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_93bdf8798f5f42718bb89b101e54c682",
      "value": 2
     }
    },
    "7d5805c372ee40cdb860c69d0d87c87b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8e66c28e3e54a3ea111ef70b229d8a9",
      "placeholder": "​",
      "style": "IPY_MODEL_23d09e6258784367bee4067b800fceb9",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "93bdf8798f5f42718bb89b101e54c682": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ae6c27aa30f34ddeba9abd06bf96cafb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b11f7e2e0acc40128f1ffc5f36b5b029": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d5805c372ee40cdb860c69d0d87c87b",
       "IPY_MODEL_7417c346afc24a98832d481d58167b69",
       "IPY_MODEL_f73f2c3f4e1347dcb0ff085a27d1927a"
      ],
      "layout": "IPY_MODEL_48d7994725b24a28ac9c79418c5111a6"
     }
    },
    "b5dbaea6b0ce4330921b1486f1c4f7d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8e66c28e3e54a3ea111ef70b229d8a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f73f2c3f4e1347dcb0ff085a27d1927a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18ab9fe8abd84251a729fefe3bfa0ad9",
      "placeholder": "​",
      "style": "IPY_MODEL_b5dbaea6b0ce4330921b1486f1c4f7d8",
      "value": " 2/2 [00:34&lt;00:00, 17.13s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
