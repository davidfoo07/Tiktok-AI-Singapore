{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11176010,"sourceType":"datasetVersion","datasetId":6975304}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"18ab9fe8abd84251a729fefe3bfa0ad9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d09e6258784367bee4067b800fceb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48d7994725b24a28ac9c79418c5111a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7417c346afc24a98832d481d58167b69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae6c27aa30f34ddeba9abd06bf96cafb","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93bdf8798f5f42718bb89b101e54c682","value":2}},"7d5805c372ee40cdb860c69d0d87c87b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e66c28e3e54a3ea111ef70b229d8a9","placeholder":"​","style":"IPY_MODEL_23d09e6258784367bee4067b800fceb9","value":"Loading checkpoint shards: 100%"}},"93bdf8798f5f42718bb89b101e54c682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae6c27aa30f34ddeba9abd06bf96cafb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11f7e2e0acc40128f1ffc5f36b5b029":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d5805c372ee40cdb860c69d0d87c87b","IPY_MODEL_7417c346afc24a98832d481d58167b69","IPY_MODEL_f73f2c3f4e1347dcb0ff085a27d1927a"],"layout":"IPY_MODEL_48d7994725b24a28ac9c79418c5111a6"}},"b5dbaea6b0ce4330921b1486f1c4f7d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8e66c28e3e54a3ea111ef70b229d8a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73f2c3f4e1347dcb0ff085a27d1927a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18ab9fe8abd84251a729fefe3bfa0ad9","placeholder":"​","style":"IPY_MODEL_b5dbaea6b0ce4330921b1486f1c4f7d8","value":" 2/2 [00:34&lt;00:00, 17.13s/it]"}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up environment","metadata":{}},{"cell_type":"markdown","source":"Check cuda version","metadata":{"id":"NdvT46W7JVp-"}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"WsGKOY7CJO_p","outputId":"faf19e6b-cd94-427a-c135-534112e1cf10","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Change CUDA memory config","metadata":{"id":"o68lGIFRPq2a"}},{"cell_type":"code","source":"!export 'PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True'","metadata":{"id":"Jg-aQ_mEPhcr","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T05:36:29.114701Z","iopub.execute_input":"2025-03-27T05:36:29.115095Z","iopub.status.idle":"2025-03-27T05:36:29.230543Z","shell.execute_reply.started":"2025-03-27T05:36:29.114966Z","shell.execute_reply":"2025-03-27T05:36:29.229549Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Install packages","metadata":{"id":"U0zIj5U8IYpW"}},{"cell_type":"code","source":"%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n%pip install --upgrade datasets transformers\n%pip install --upgrade qwen-vl-utils[decord]","metadata":{"id":"qxeL2VoxJDIj","outputId":"8a8366e4-eb9a-47f3-b3ef-96e2f94e6224","trusted":true,"execution":{"iopub.status.busy":"2025-03-27T05:36:30.930911Z","iopub.execute_input":"2025-03-27T05:36:30.931218Z","iopub.status.idle":"2025-03-27T05:36:57.844173Z","shell.execute_reply.started":"2025-03-27T05:36:30.931193Z","shell.execute_reply":"2025-03-27T05:36:57.843277Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu126\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.3.1)\nCollecting datasets\n  Downloading datasets-3.4.1-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\nCollecting transformers\n  Downloading transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.17.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.12)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2025.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->datasets) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading datasets-3.4.1-py3-none-any.whl (487 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading transformers-4.50.1-py3-none-any.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers, datasets\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.47.0\n    Uninstalling transformers-4.47.0:\n      Successfully uninstalled transformers-4.47.0\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.3.1\n    Uninstalling datasets-3.3.1:\n      Successfully uninstalled datasets-3.3.1\nSuccessfully installed datasets-3.4.1 transformers-4.50.1\nNote: you may need to restart the kernel to use updated packages.\nCollecting qwen-vl-utils[decord]\n  Downloading qwen_vl_utils-0.0.10-py3-none-any.whl.metadata (6.3 kB)\nCollecting av (from qwen-vl-utils[decord])\n  Downloading av-14.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils[decord]) (24.2)\nRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils[decord]) (11.0.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from qwen-vl-utils[decord]) (2.32.3)\nCollecting decord (from qwen-vl-utils[decord])\n  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\nRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from decord->qwen-vl-utils[decord]) (1.26.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils[decord]) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils[decord]) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils[decord]) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->qwen-vl-utils[decord]) (2025.1.31)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->decord->qwen-vl-utils[decord]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->decord->qwen-vl-utils[decord]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->decord->qwen-vl-utils[decord]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.14.0->decord->qwen-vl-utils[decord]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.14.0->decord->qwen-vl-utils[decord]) (2024.2.0)\nDownloading av-14.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.8/38.8 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading qwen_vl_utils-0.0.10-py3-none-any.whl (6.7 kB)\nInstalling collected packages: av, qwen-vl-utils, decord\nSuccessfully installed av-14.2.0 decord-0.6.0 qwen-vl-utils-0.0.10\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Using pre-trained Qwen 2.5-VL multiple times","metadata":{}},{"cell_type":"markdown","source":"Import packages","metadata":{"id":"IQdxPe5HOCAo"}},{"cell_type":"code","source":"import gc\nimport time\nimport os\nimport csv\nimport torch\nfrom datasets import load_dataset\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info","metadata":{"execution":{"iopub.status.busy":"2025-03-27T05:36:59.353555Z","iopub.execute_input":"2025-03-27T05:36:59.353868Z","iopub.status.idle":"2025-03-27T05:37:30.382824Z","shell.execute_reply.started":"2025-03-27T05:36:59.353841Z","shell.execute_reply":"2025-03-27T05:37:30.382106Z"},"id":"6pCgmEBcN-sq","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Clear GPU memory","metadata":{"id":"LGg2utA_JGyw"}},{"cell_type":"code","source":"def clear_memory():\n    # Delete variables if they exist in the current global scope\n    if \"inputs\" in globals():\n        del globals()[\"inputs\"]\n    if \"model\" in globals():\n        del globals()[\"model\"]\n    if \"processor\" in globals():\n        del globals()[\"processor\"]\n    time.sleep(2)\n\n    # Garbage collection and clearing CUDA memory\n    gc.collect()\n    time.sleep(2)\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n    time.sleep(2)\n    gc.collect()\n    time.sleep(2)\n\n    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n\nclear_memory()","metadata":{"id":"0XTFbh7QKCqP","outputId":"e2c97d6b-2c9a-4a1f-be03-f80955b61589","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load dataset and model","metadata":{"id":"AF2UMdBjKH_K"}},{"cell_type":"code","source":"dataset = load_dataset(\"lmms-lab/AISG_Challenge\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n    torch_dtype=torch.float16,\n    device_map=device)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")","metadata":{"execution":{"iopub.status.busy":"2025-03-27T05:37:33.167574Z","iopub.execute_input":"2025-03-27T05:37:33.168241Z","iopub.status.idle":"2025-03-27T05:38:22.760486Z","shell.execute_reply.started":"2025-03-27T05:37:33.168207Z","shell.execute_reply":"2025-03-27T05:38:22.759470Z"},"id":"bWUoIoHuKK0n","outputId":"dce77522-e396-416e-9c57-d64a9dd45a08","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.26k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce96e09bdb44b11bd55be30d69e0517"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/94.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c422332ff30a4105a952814a1ccb6ac4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"319b2048b6694714a8269b96f7e403a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80149e6eafc40f087607fbf148b43fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a722de0937824bd0b8acc7352e73efbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ead6e8e83494a0a8df88e160c98c7e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacf510692ab4bf7a8f2498df75631cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"849170b5b0de485a90e769a7fafc6463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e798f0a6a9a498684002e44ff59db90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67f06238794b4c1094433d87ccd0cfe1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a03c2cc673b4dd4b726f1251a6cca6c"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.50, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9e38ad8eb3b4a61911a29a52440d3d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52c07e6800124e38acf23f5d3d994ebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c41cfb980c64bcbbbd9032ec692734d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b14bc944c5e47029c828f1978d54142"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"472c88babc584d1fb228962bcc69963a"}},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"Download video function","metadata":{"id":"_VIcN_9gKVbk"}},{"cell_type":"code","source":"def retrieve_video(video_id):\n    filename = f\"{video_id}.mp4\"\n    video_path = f\"../input/videos/videos/{filename}\"\n    return video_path","metadata":{"execution":{"iopub.status.busy":"2025-03-27T05:38:27.413198Z","iopub.execute_input":"2025-03-27T05:38:27.413489Z","iopub.status.idle":"2025-03-27T05:38:27.417559Z","shell.execute_reply.started":"2025-03-27T05:38:27.413467Z","shell.execute_reply":"2025-03-27T05:38:27.416285Z"},"id":"FOr5RWLAKS1m","trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"Process sample","metadata":{"id":"Bii44pICKZmU"}},{"cell_type":"code","source":"def process_test_case(example):\n    video_id = example[\"video_id\"]\n    question = example[\"question\"]\n    question_prompt = example[\"question_prompt\"]\n    expected_answer = example[\"answer\"]\n    video_path = retrieve_video(video_id)\n\n    conversation = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": f\"Make a better prompt from the question\\nQuestion:\\n{question}\\n\"},\n            ],\n        }\n    ]\n\n    text = processor.apply_chat_template(\n        conversation, tokenize=False, add_generation_prompt=True\n    )\n    inputs = processor(\n        text=[text],\n        padding=True,\n        return_tensors=\"pt\",\n    )\n    inputs = inputs.to(model.device)\n    generated_ids = model.generate(**inputs, max_new_tokens=128)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    improved_prompt = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )[0]\n    \n    conversation = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"video\",\n                    \"video\": video_path,\n                    \"max_pixels\": 135 * 240,\n                    \"fps\": 1,\n                },\n                {\"type\": \"text\", \"text\": f\"Summarize the video in as much details as possible.\"},\n            ],\n        }\n    ]\n\n    text = processor.apply_chat_template(\n        conversation, tokenize=False, add_generation_prompt=True\n    )\n    image_inputs, video_inputs, video_kwargs = process_vision_info(conversation, return_video_kwargs=True)\n    inputs = processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n        **video_kwargs,\n    )\n    inputs = inputs.to(model.device)\n    generated_ids = model.generate(**inputs, max_new_tokens=1280)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    video_summary = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )[0]\n\n    conversation = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"video\",\n                    \"video\": video_path,\n                    \"max_pixels\": 135 * 240,\n                    \"fps\": 1,\n                },\n                {\"type\": \"text\", \"text\": f\"Improved prompt:\\n{improved_prompt}\\nVideo summary:\\n{video_summary}\\nOriginal question:\\n{question}\\n{question_prompt}\"},\n            ],\n        }\n    ]\n\n    text = processor.apply_chat_template(\n        conversation, tokenize=False, add_generation_prompt=True\n    )\n    image_inputs, video_inputs, video_kwargs = process_vision_info(conversation, return_video_kwargs=True)\n    inputs = processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n        **video_kwargs,\n    )\n    inputs = inputs.to(model.device)\n\n    generated_ids = model.generate(**inputs, max_new_tokens=1280)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    output_text = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )[0]\n    '''\n    print(f\"Prompt:\\nImproved prompt:\\n{improved_prompt}\\nVideo summary:\\n{video_summary}\\nOriginal question:\\n{question}\\n{question_prompt}\")\n    print(f\"Video URL: {example['youtube_url']}\")\n    print(f\"Question:\\n{question}\\n{question_prompt}\")\n    print(f\"Answer: {output_text}\")\n    '''\n    return example['qid'], output_text","metadata":{"execution":{"iopub.status.busy":"2025-03-27T05:39:47.453668Z","iopub.execute_input":"2025-03-27T05:39:47.454077Z","iopub.status.idle":"2025-03-27T05:39:47.464695Z","shell.execute_reply.started":"2025-03-27T05:39:47.454047Z","shell.execute_reply":"2025-03-27T05:39:47.463665Z"},"id":"FOu2jwkdKeGq","trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"Run a test case","metadata":{"id":"sKsDjKFWKjKv"}},{"cell_type":"code","source":"start_time = time.time()\noutput_file = \"./results.csv\"\nwith open(output_file, mode=\"w\", newline=\"\") as file:\n    writer = csv.writer(file)\n    writer.writerow([\"qid\", \"pred\"])\n    '''\n    sample = dataset['test'].filter(lambda x: x['qid'] == '0957-7')[0]\n    qid, pred = process_test_case(sample)\n    writer.writerow([qid, pred])\n    '''\n    for sample in dataset['test']:\n        print(f\"processing qid {sample['qid']}\")\n        qid, pred = process_test_case(sample)\n        writer.writerow([qid, pred])\nend_time = time.time()\nprint(f\"Time taken: {end_time - start_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2025-03-27T05:39:51.253474Z","iopub.execute_input":"2025-03-27T05:39:51.253798Z","iopub.status.idle":"2025-03-27T05:40:29.776083Z","shell.execute_reply.started":"2025-03-27T05:39:51.253769Z","shell.execute_reply":"2025-03-27T05:40:29.775110Z"},"id":"TC2df2I0vPXv","trusted":true},"outputs":[{"name":"stdout","text":"Time taken: 38.516945362091064 seconds\n","output_type":"stream"}],"execution_count":9}]}