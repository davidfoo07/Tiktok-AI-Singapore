{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11176010,"sourceType":"datasetVersion","datasetId":6975304}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"widgets":{"application/vnd.jupyter.widget-state+json":{"18ab9fe8abd84251a729fefe3bfa0ad9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23d09e6258784367bee4067b800fceb9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48d7994725b24a28ac9c79418c5111a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7417c346afc24a98832d481d58167b69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae6c27aa30f34ddeba9abd06bf96cafb","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93bdf8798f5f42718bb89b101e54c682","value":2}},"7d5805c372ee40cdb860c69d0d87c87b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8e66c28e3e54a3ea111ef70b229d8a9","placeholder":"​","style":"IPY_MODEL_23d09e6258784367bee4067b800fceb9","value":"Loading checkpoint shards: 100%"}},"93bdf8798f5f42718bb89b101e54c682":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ae6c27aa30f34ddeba9abd06bf96cafb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b11f7e2e0acc40128f1ffc5f36b5b029":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7d5805c372ee40cdb860c69d0d87c87b","IPY_MODEL_7417c346afc24a98832d481d58167b69","IPY_MODEL_f73f2c3f4e1347dcb0ff085a27d1927a"],"layout":"IPY_MODEL_48d7994725b24a28ac9c79418c5111a6"}},"b5dbaea6b0ce4330921b1486f1c4f7d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8e66c28e3e54a3ea111ef70b229d8a9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f73f2c3f4e1347dcb0ff085a27d1927a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18ab9fe8abd84251a729fefe3bfa0ad9","placeholder":"​","style":"IPY_MODEL_b5dbaea6b0ce4330921b1486f1c4f7d8","value":" 2/2 [00:34&lt;00:00, 17.13s/it]"}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setting up environment","metadata":{},"attachments":{}},{"cell_type":"markdown","source":"Check cuda version","metadata":{"id":"NdvT46W7JVp-"},"attachments":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"WsGKOY7CJO_p","outputId":"faf19e6b-cd94-427a-c135-534112e1cf10","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Change CUDA memory config","metadata":{"id":"o68lGIFRPq2a"},"attachments":{}},{"cell_type":"code","source":"!export 'PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True'","metadata":{"id":"Jg-aQ_mEPhcr","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Install packages","metadata":{"id":"U0zIj5U8IYpW"},"attachments":{}},{"cell_type":"code","source":"%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\n%pip install --upgrade datasets transformers\n%pip install --upgrade qwen-vl-utils[decord]","metadata":{"id":"qxeL2VoxJDIj","outputId":"8a8366e4-eb9a-47f3-b3ef-96e2f94e6224","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Using pre-trained Qwen 2.5-VL multiple times","metadata":{},"attachments":{}},{"cell_type":"markdown","source":"Import packages","metadata":{"id":"IQdxPe5HOCAo"},"attachments":{}},{"cell_type":"code","source":"import gc\nimport time\nimport csv\nimport torch\nfrom datasets import load_dataset\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info","metadata":{"execution":{"iopub.status.busy":"2025-03-31T12:34:40.822615Z","iopub.execute_input":"2025-03-31T12:34:40.822984Z","iopub.status.idle":"2025-03-31T12:34:48.073151Z","shell.execute_reply.started":"2025-03-31T12:34:40.822934Z","shell.execute_reply":"2025-03-31T12:34:48.072236Z"},"id":"6pCgmEBcN-sq","trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"Clear GPU memory","metadata":{"id":"LGg2utA_JGyw"},"attachments":{}},{"cell_type":"code","source":"def clear_memory():\n    # Delete variables if they exist in the current global scope\n    if \"inputs\" in globals():\n        del globals()[\"inputs\"]\n    if \"model\" in globals():\n        del globals()[\"model\"]\n    if \"processor\" in globals():\n        del globals()[\"processor\"]\n    time.sleep(2)\n\n    # Garbage collection and clearing CUDA memory\n    gc.collect()\n    time.sleep(2)\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n    time.sleep(2)\n    gc.collect()\n    time.sleep(2)\n\n    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n\nclear_memory()","metadata":{"id":"0XTFbh7QKCqP","outputId":"e2c97d6b-2c9a-4a1f-be03-f80955b61589","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Load dataset and model","metadata":{"id":"AF2UMdBjKH_K"},"attachments":{}},{"cell_type":"code","source":"dataset = load_dataset(\"lmms-lab/AISG_Challenge\")\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nmodel = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    \"Qwen/Qwen2.5-VL-3B-Instruct\",\n    torch_dtype=torch.float16,\n    device_map=device)\nprocessor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")","metadata":{"execution":{"iopub.status.busy":"2025-03-31T12:34:57.076213Z","iopub.execute_input":"2025-03-31T12:34:57.076609Z","iopub.status.idle":"2025-03-31T12:35:29.544652Z","shell.execute_reply.started":"2025-03-31T12:34:57.076578Z","shell.execute_reply":"2025-03-31T12:35:29.543900Z"},"id":"bWUoIoHuKK0n","outputId":"dce77522-e396-416e-9c57-d64a9dd45a08","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.37k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b4177ec019f4c9288d368ab80be40b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/65.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300d8326e20442de978e89896ed78667"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51375ba41f5b4927b39d7742b84d009e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33e3279e97d84170a6a19fac51b561b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/3.53G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6ec9fa0fd0a4c14af1a62f82658bce1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92576c2d453e49f6800f0c4a2adb144e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/216 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"003d71512a8b4a8987c3306673ddefa7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bf861a2df1247b294e46222884df318"}},"metadata":{}},{"name":"stderr","text":"Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e2b4ba7c38e441f8880d46d5a934af5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bed9879b2f654df9906d9a9078c812d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22a27b7d22094072943d787543313e0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b200f7f872434d40bc22ffb06b57a838"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c0c4d518f5e425aa6056e152f634fff"}},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"Download video function","metadata":{"id":"_VIcN_9gKVbk"},"attachments":{}},{"cell_type":"code","source":"def retrieve_video(video_id):\n    filename = f\"{video_id}.mp4\"\n    video_path = f\"../input/videos/{filename}\"\n    return video_path","metadata":{"execution":{"iopub.status.busy":"2025-03-31T12:37:17.162980Z","iopub.execute_input":"2025-03-31T12:37:17.163354Z","iopub.status.idle":"2025-03-31T12:37:17.167557Z","shell.execute_reply.started":"2025-03-31T12:37:17.163320Z","shell.execute_reply":"2025-03-31T12:37:17.166783Z"},"id":"FOr5RWLAKS1m","trusted":true},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"Process sample","metadata":{"id":"Bii44pICKZmU"},"attachments":{}},{"cell_type":"code","source":"def process_test_case(example):\n    video_id = example[\"video_id\"]\n    question = example[\"question\"]\n    question_prompt = example[\"question_prompt\"]\n    expected_answer = example[\"answer\"]\n    video_path = retrieve_video(video_id)\n\n    conversation = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"video\",\n                    \"video\": video_path,\n                    \"max_pixels\": 135 * 240,\n                    \"fps\": 1,\n                },\n                {\"type\": \"text\", \"text\": f\"{question}\\n{question_prompt}\"},\n            ],\n        }\n    ]\n\n    text = processor.apply_chat_template(\n        conversation, tokenize=False, add_generation_prompt=True\n    )\n    image_inputs, video_inputs, video_kwargs = process_vision_info(conversation, return_video_kwargs=True)\n    inputs = processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\",\n        **video_kwargs,\n    )\n    inputs = inputs.to(model.device)\n\n    generated_ids = model.generate(**inputs, max_new_tokens=1280)\n    generated_ids_trimmed = [\n        out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n    ]\n    output_text = processor.batch_decode(\n        generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n    )[0]\n    '''\n    print(f\"Prompt:\\n{question}\\n{question_prompt}\")\n    print(f\"Video URL: {example['youtube_url']}\")\n    print(f\"Question:\\n{question}\\n{question_prompt}\")\n    print(f\"Answer: {output_text}\")\n    '''\n    return example['qid'], output_text","metadata":{"execution":{"iopub.status.busy":"2025-03-31T12:37:48.491649Z","iopub.execute_input":"2025-03-31T12:37:48.492027Z","iopub.status.idle":"2025-03-31T12:37:48.498551Z","shell.execute_reply.started":"2025-03-31T12:37:48.491993Z","shell.execute_reply":"2025-03-31T12:37:48.497631Z"},"id":"FOu2jwkdKeGq","trusted":true},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"Run a test case","metadata":{"id":"sKsDjKFWKjKv"},"attachments":{}},{"cell_type":"code","source":"start_time = time.time()\noutput_file = \"./results.csv\"\nwith open(output_file, mode=\"w\", newline=\"\") as file:\n    writer = csv.writer(file)\n    writer.writerow([\"qid\", \"pred\"])\n    sample = dataset['test'].filter(lambda x: x['qid'] == '0957-7')[0]\n    qid, pred = process_test_case(sample)\n    writer.writerow([qid, pred])\n    '''\n    for sample in dataset['test']:\n        print(f\"processing qid {sample['qid']}\")\n        qid, pred = process_test_case(sample)\n        writer.writerow([qid, pred])\n    '''\nend_time = time.time()\nprint(f\"Time taken: {end_time - start_time} seconds\")","metadata":{"execution":{"iopub.status.busy":"2025-03-31T12:37:50.533272Z","iopub.execute_input":"2025-03-31T12:37:50.533603Z"},"id":"TC2df2I0vPXv","trusted":true},"outputs":[],"execution_count":null}]}